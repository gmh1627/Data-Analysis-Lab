{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# 对实验3的数据集进行预处理\n",
    "\n",
    "df1 = pd.read_csv('3_data.csv',encoding='utf-8')\n",
    "\n",
    "df1 = df1.dropna()\n",
    "\n",
    "df1 = df1.reset_index(drop=True)\n",
    "\n",
    "df1 = df1.drop('id', axis=1)\n",
    "\n",
    "df1['diagnosis'] = df1['diagnosis'].apply(lambda x: 0 if x == 'B' else 1)#.apply()方法将函数应用于指定位置的每个元素\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Logistic Regression on Validation Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.91      0.95        11\n",
      "           1       0.88      1.00      0.93         7\n",
      "\n",
      "    accuracy                           0.94        18\n",
      "   macro avg       0.94      0.95      0.94        18\n",
      "weighted avg       0.95      0.94      0.94        18\n",
      "\n",
      "Classification Report for Logistic Regression on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94        24\n",
      "           1       0.92      0.86      0.89        14\n",
      "\n",
      "    accuracy                           0.92        38\n",
      "   macro avg       0.92      0.91      0.91        38\n",
      "weighted avg       0.92      0.92      0.92        38\n",
      "\n",
      "Classification Report for Random Forest on Validation Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        11\n",
      "           1       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        18\n",
      "   macro avg       1.00      1.00      1.00        18\n",
      "weighted avg       1.00      1.00      1.00        18\n",
      "\n",
      "Classification Report for Random Forest on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96        24\n",
      "           1       1.00      0.86      0.92        14\n",
      "\n",
      "    accuracy                           0.95        38\n",
      "   macro avg       0.96      0.93      0.94        38\n",
      "weighted avg       0.95      0.95      0.95        38\n",
      "\n",
      "Classification Report for SVM on Validation Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        11\n",
      "           1       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        18\n",
      "   macro avg       1.00      1.00      1.00        18\n",
      "weighted avg       1.00      1.00      1.00        18\n",
      "\n",
      "Classification Report for SVM on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.92        24\n",
      "           1       1.00      0.71      0.83        14\n",
      "\n",
      "    accuracy                           0.89        38\n",
      "   macro avg       0.93      0.86      0.88        38\n",
      "weighted avg       0.91      0.89      0.89        38\n",
      "\n",
      "Classification Report for Decision Tree on Validation Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96        11\n",
      "           1       1.00      0.86      0.92         7\n",
      "\n",
      "    accuracy                           0.94        18\n",
      "   macro avg       0.96      0.93      0.94        18\n",
      "weighted avg       0.95      0.94      0.94        18\n",
      "\n",
      "Classification Report for Decision Tree on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94        24\n",
      "           1       0.92      0.86      0.89        14\n",
      "\n",
      "    accuracy                           0.92        38\n",
      "   macro avg       0.92      0.91      0.91        38\n",
      "weighted avg       0.92      0.92      0.92        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Split data\n",
    "X = df1.drop('diagnosis', axis=1)\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df1['diagnosis'])\n",
    "\n",
    "# Split data\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.125, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size=0.67, random_state=42)\n",
    "\n",
    "# Define classifiers\n",
    "classifiers = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=3000),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"SVM\": SVC(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "}\n",
    "\n",
    "# Train and evaluate classifiers\n",
    "for name, clf in classifiers.items():\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_val)\n",
    "    print(f\"Classification Report for {name} on Validation Set:\")\n",
    "    print(classification_report(y_val, y_pred))\n",
    "    \n",
    "    # After tuning parameters on validation set, evaluate on test set\n",
    "    y_pred_test = clf.predict(X_test)\n",
    "    print(f\"Classification Report for {name} on Test Set:\")\n",
    "    print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Class age menopause tumor-size inv-nodes node-caps  \\\n",
      "0    no-recurrence-events   4        13         20        26        40   \n",
      "1    no-recurrence-events   5        13         18        26        40   \n",
      "2    no-recurrence-events   5        13         18        26        40   \n",
      "3    no-recurrence-events   7        12         17        26        40   \n",
      "4    no-recurrence-events   5        13         14        26        40   \n",
      "..                    ...  ..       ...        ...       ...       ...   \n",
      "281     recurrence-events   4        13         20        26        40   \n",
      "282     recurrence-events   4        13         18        26        40   \n",
      "283     recurrence-events   7        12         18        26        40   \n",
      "284     recurrence-events   5        12         20        27        40   \n",
      "285     recurrence-events   6        12         20        27        40   \n",
      "\n",
      "     deg-malig breast breast-quad irradiat  \n",
      "0           43     44          47       52  \n",
      "1           42     45          48       52  \n",
      "2           42     44          47       52  \n",
      "3           42     45          46       52  \n",
      "4           42     45          49       52  \n",
      "..         ...    ...         ...      ...  \n",
      "281         42     44          46       52  \n",
      "282         43     44          46       51  \n",
      "283         41     45          46       52  \n",
      "284         43     44          47       52  \n",
      "285         43     44          47       52  \n",
      "\n",
      "[277 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 对实验4的数据集进行预处理\n",
    "df = pd.read_csv('4_data.csv')\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "df = df.drop('id', axis=1)\n",
    "\n",
    "replace_values1 = {'14-Oct': '10-14', '9-May': '5-9'}\n",
    "df['tumor-size'] = df['tumor-size'].replace(replace_values1)\n",
    "\n",
    "replace_values2 = {'5-Mar': '3-5', '8-Jun': '6-8', '11-Sep': '9-11', '14-Dec': '12-14'}\n",
    "df['inv-nodes'] = df['inv-nodes'].replace(replace_values2)\n",
    "\n",
    "excel = pd.read_excel('4_variables.xlsx', index_col=0)\n",
    "temp1_variables = excel['Description'].tolist()\n",
    "temp2_variables = [item.split(', ') for item in temp1_variables]\n",
    "variables = []\n",
    "for item in temp2_variables:\n",
    "    for sublist in item:\n",
    "        variables.append(sublist)\n",
    "\n",
    "for column in df.columns[1:]:\n",
    "    if column == 'irradiat':\n",
    "        for i in df.index:\n",
    "            first_index = variables.index(df.loc[i, column])\n",
    "            second_index = variables[first_index+1:].index(df.loc[i, column]) + first_index + 1\n",
    "            df.loc[i, column] = second_index\n",
    "    else:\n",
    "        for i in df.index:\n",
    "            df.loc[i, column] = variables.index(str(df.loc[i, column]))\n",
    "            \n",
    "ind2val = {}\n",
    "\n",
    "for attribute, row in excel.iterrows():\n",
    "    if attribute != 'irradiat':\n",
    "        for item in row['Description'].split(', '):\n",
    "            index = variables.index(item)\n",
    "            ind2val[index] = f\"{attribute}={item}\"\n",
    "    else:\n",
    "        for item in row['Description'].split(', '):\n",
    "            first_index = variables.index(item)\n",
    "            second_index = variables[first_index+1:].index(item) + first_index + 1\n",
    "            index = second_index\n",
    "            ind2val[index] = f\"{attribute}={item}\"\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Logistic Regression on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.95      0.82        37\n",
      "           1       0.75      0.32      0.44        19\n",
      "\n",
      "    accuracy                           0.73        56\n",
      "   macro avg       0.74      0.63      0.63        56\n",
      "weighted avg       0.74      0.73      0.69        56\n",
      "\n",
      "Classification Report for Random Forest on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.81      0.76        37\n",
      "           1       0.50      0.37      0.42        19\n",
      "\n",
      "    accuracy                           0.66        56\n",
      "   macro avg       0.61      0.59      0.59        56\n",
      "weighted avg       0.64      0.66      0.65        56\n",
      "\n",
      "Classification Report for Logistic Regression on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.90      0.84        42\n",
      "           1       0.43      0.21      0.29        14\n",
      "\n",
      "    accuracy                           0.73        56\n",
      "   macro avg       0.60      0.56      0.56        56\n",
      "weighted avg       0.69      0.73      0.70        56\n",
      "\n",
      "Classification Report for Random Forest on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.90      0.84        42\n",
      "           1       0.50      0.29      0.36        14\n",
      "\n",
      "    accuracy                           0.75        56\n",
      "   macro avg       0.65      0.60      0.60        56\n",
      "weighted avg       0.72      0.75      0.72        56\n",
      "\n",
      "Classification Report for Logistic Regression on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.85      0.80        39\n",
      "           1       0.45      0.31      0.37        16\n",
      "\n",
      "    accuracy                           0.69        55\n",
      "   macro avg       0.60      0.58      0.58        55\n",
      "weighted avg       0.66      0.69      0.67        55\n",
      "\n",
      "Classification Report for Random Forest on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.82      0.79        39\n",
      "           1       0.46      0.38      0.41        16\n",
      "\n",
      "    accuracy                           0.69        55\n",
      "   macro avg       0.61      0.60      0.60        55\n",
      "weighted avg       0.67      0.69      0.68        55\n",
      "\n",
      "Classification Report for Logistic Regression on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      1.00      0.86        38\n",
      "           1       1.00      0.29      0.45        17\n",
      "\n",
      "    accuracy                           0.78        55\n",
      "   macro avg       0.88      0.65      0.66        55\n",
      "weighted avg       0.83      0.78      0.74        55\n",
      "\n",
      "Classification Report for Random Forest on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.95      0.87        38\n",
      "           1       0.80      0.47      0.59        17\n",
      "\n",
      "    accuracy                           0.80        55\n",
      "   macro avg       0.80      0.71      0.73        55\n",
      "weighted avg       0.80      0.80      0.78        55\n",
      "\n",
      "Classification Report for Logistic Regression on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.85      0.82        40\n",
      "           1       0.50      0.40      0.44        15\n",
      "\n",
      "    accuracy                           0.73        55\n",
      "   macro avg       0.65      0.62      0.63        55\n",
      "weighted avg       0.71      0.73      0.72        55\n",
      "\n",
      "Classification Report for Random Forest on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.80      0.82        40\n",
      "           1       0.53      0.60      0.56        15\n",
      "\n",
      "    accuracy                           0.75        55\n",
      "   macro avg       0.69      0.70      0.69        55\n",
      "weighted avg       0.76      0.75      0.75        55\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Prepare data\n",
    "X = df.drop('Class', axis=1)\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df['Class'])\n",
    "\n",
    "# Define classifiers\n",
    "classifiers = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Random Forest\": RandomForestClassifier()\n",
    "}\n",
    "\n",
    "# 使用k折交叉验证法划分训练集/测试集（可调整随机种子以获得不同的划分方案）\n",
    "# Define k-fold cross validation\n",
    "kf = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "\n",
    "# Perform k-fold cross validation\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Train and evaluate classifiers\n",
    "    for name, clf in classifiers.items():\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        print(f\"Classification Report for {name} on Test Set:\")\n",
    "        print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
