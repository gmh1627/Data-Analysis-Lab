{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id             0\n",
      "Class          0\n",
      "age            0\n",
      "menopause      0\n",
      "tumor-size     0\n",
      "inv-nodes      0\n",
      "node-caps      8\n",
      "deg-malig      0\n",
      "breast         0\n",
      "breast-quad    1\n",
      "irradiat       0\n",
      "dtype: int64\n",
      "tumor-size\n",
      "30-34     57\n",
      "25-29     51\n",
      "20-24     48\n",
      "15-19     29\n",
      "14-Oct    28\n",
      "40-44     22\n",
      "35-39     19\n",
      "0-4        8\n",
      "50-54      8\n",
      "9-May      4\n",
      "45-49      3\n",
      "Name: count, dtype: int64\n",
      "inv-nodes\n",
      "0-2       209\n",
      "5-Mar      34\n",
      "8-Jun      17\n",
      "11-Sep      7\n",
      "15-17       6\n",
      "14-Dec      3\n",
      "24-26       1\n",
      "Name: count, dtype: int64\n",
      "{0: 'Class=no-recurrence-events', 1: 'Class=recurrence-events', 2: 'age=10-19', 3: 'age=20-29', 4: 'age=30-39', 5: 'age=40-49', 6: 'age=50-59', 7: 'age=60-69', 8: 'age=70-79', 9: 'age=80-89', 10: 'age=90-99', 11: 'menopause=lt40', 12: 'menopause=ge40', 13: 'menopause=premeno', 14: 'tumor-size=0-4', 15: 'tumor-size=5-9', 16: 'tumor-size=10-14', 17: 'tumor-size=15-19', 18: 'tumor-size=20-24', 19: 'tumor-size=25-29', 20: 'tumor-size=30-34', 21: 'tumor-size=35-39', 22: 'tumor-size=40-44', 23: 'tumor-size=45-49', 24: 'tumor-size=50-54', 25: 'tumor-size=55-59', 26: 'inv-nodes=0-2', 27: 'inv-nodes=3-5', 28: 'inv-nodes=6-8', 29: 'inv-nodes=9-11', 30: 'inv-nodes=12-14', 31: 'inv-nodes=15-17', 32: 'inv-nodes=18-20', 33: 'inv-nodes=21-23', 34: 'inv-nodes=24-26', 35: 'inv-nodes=27-29', 36: 'inv-nodes=30-32', 37: 'inv-nodes=33-35', 38: 'inv-nodes=36-39', 39: 'node-caps=yes', 40: 'node-caps=no', 41: 'deg-malig=1', 42: 'deg-malig=2', 43: 'deg-malig=3', 44: 'breast=left', 45: 'breast=right', 46: 'breast-quad=left_up', 47: 'breast-quad=left_low', 48: 'breast-quad=right_up', 49: 'breast-quad=right_low', 50: 'breast-quad=central', 51: 'irradiat=yes', 52: 'irradiat=no'}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Task1\n",
    "df = pd.read_csv('data2.csv')\n",
    "\n",
    "# Q1\n",
    "print(df.isnull().sum())\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "# Q2\n",
    "print(df['tumor-size'].value_counts())\n",
    "print(df['inv-nodes'].value_counts())\n",
    "\n",
    "replace_values1 = {'14-Oct': '10-14', '9-May': '5-9'}\n",
    "df['tumor-size'] = df['tumor-size'].replace(replace_values1)\n",
    "\n",
    "replace_values2 = {'5-Mar': '3-5', '8-Jun': '6-8', '11-Sep': '9-11', '14-Dec': '12-14'}\n",
    "df['inv-nodes'] = df['inv-nodes'].replace(replace_values2)\n",
    "\n",
    "# Q3\n",
    "excel = pd.read_excel('variables.xlsx', index_col=0)\n",
    "temp1_variables = excel['Description'].tolist()\n",
    "temp2_variables = [item.split(', ') for item in temp1_variables]\n",
    "variables = []\n",
    "for item in temp2_variables:\n",
    "    for sublist in item:\n",
    "        variables.append(sublist)\n",
    "\n",
    "for column in df.columns[1:]:\n",
    "    if column == 'irradiat':\n",
    "        for i in df.index:\n",
    "            first_index = variables.index(df.loc[i, column])\n",
    "            second_index = variables[first_index+1:].index(df.loc[i, column]) + first_index + 1\n",
    "            df.loc[i, column] = second_index\n",
    "    else:\n",
    "        for i in df.index:\n",
    "            df.loc[i, column] = variables.index(str(df.loc[i, column]))\n",
    "            \n",
    "ind2val = {}\n",
    "\n",
    "for attribute, row in excel.iterrows():\n",
    "    if attribute != 'irradiat':\n",
    "        for item in row['Description'].split(', '):\n",
    "            index = variables.index(item)\n",
    "            ind2val[index] = f\"{attribute}={item}\"\n",
    "    else:\n",
    "        for item in row['Description'].split(', '):\n",
    "            first_index = variables.index(item)\n",
    "            second_index = variables[first_index+1:].index(item) + first_index + 1\n",
    "            index = second_index\n",
    "            ind2val[index] = f\"{attribute}={item}\"\n",
    "print(ind2val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequent 1-itemsets: [{0}, {12}, {13}, {26}, {40}, {42}, {44}, {45}, {52}]\n",
      "Frequent 2-itemsets: [{40, 13}, {26, 13}, {40, 44}, {26, 44}, {0, 26}, {26, 52}, {0, 40}, {0, 52}, {40, 52}, {44, 52}, {52, 13}, {40, 26}]\n",
      "Frequent 3-itemsets: [{0, 40, 52}, {40, 26, 52}, {0, 26, 52}, {0, 26, 40}]\n",
      "Frequent 4-itemsets: [{0, 40, 26, 52}]\n",
      "{26}->{0}: cof = 0.7942583732057417, lift = 1.122497802948931\n",
      "{40}->{0}: cof = 0.7737556561085973, lift = 1.0935220241942931\n",
      "{52}->{0}: cof = 0.7627906976744185, lift = 1.0780256288561936\n",
      "{40, 52}->{0}: cof = 0.8074866310160427, lift = 1.1411928407726726\n",
      "{26, 52}->{0}: cof = 0.8166666666666667, lift = 1.1541666666666668\n",
      "{40, 26}->{0}: cof = 0.7999999999999999, lift = 1.1306122448979592\n",
      "{40, 26, 52}->{0}: cof = 0.8238636363636364, lift = 1.1643378942486087\n"
     ]
    }
   ],
   "source": [
    "# Task2\n",
    "# Q1\n",
    "\n",
    "# Calulate the support rate of each itemset\n",
    "def calculate_support(df, itemsets):\n",
    "    support_rate = {}\n",
    "    for itemset in itemsets:\n",
    "        if itemset:\n",
    "            num = df.apply(lambda row: all(item in set(row) for item in itemset), axis=1).sum()\n",
    "            # 接受一个参数row，表示df的一行数据，检查itemset中的所有元素是否都在row中出现，若都出现则返回True，否则返回False\n",
    "            support = num / len(df)\n",
    "            support_rate[frozenset(itemset)] = support\n",
    "    return support_rate\n",
    "\n",
    "# Generate frequent k-itemsets\n",
    "def generate_frequent(df, Candidate_k, min_support=0.4):\n",
    "    Frequent_k = []\n",
    "    support_rate = calculate_support(df, Candidate_k)\n",
    "    for itemset in Candidate_k:\n",
    "        if support_rate[frozenset(itemset)] >= min_support:\n",
    "            Frequent_k.append(itemset)\n",
    "\n",
    "    return Frequent_k\n",
    "\n",
    "# Generate candidate k-itemsets\n",
    "def generate_candidate(last_frequent, k):\n",
    "    Candidate_k = []\n",
    "    for i in range(len(last_frequent)):\n",
    "        for j in range(i+1, len(last_frequent)):\n",
    "            new_set = last_frequent[i] | last_frequent[j]\n",
    "            if len(new_set) == k:\n",
    "                all_subsets_in_last_frequent = True\n",
    "                for item in new_set:# 检验new_set的所有子集是否都在last_frequent中\n",
    "                    if new_set - {item} not in last_frequent:\n",
    "                        all_subsets_in_last_frequent = False\n",
    "                        break\n",
    "                if all_subsets_in_last_frequent:        \n",
    "                    Candidate_k.append(new_set)\n",
    "    Candidate_k = list(set(map(frozenset, Candidate_k)))# 使用 map() 函数对 Candidate_k 列表中的每个元素都应用 frozenset() 函数\n",
    "    return Candidate_k\n",
    "\n",
    "frequent_itemsets = {}\n",
    "k = 1\n",
    "candidates = [{i} for i in range(len(variables))]\n",
    "\n",
    "while True:\n",
    "    frequent = [set(x) for x in generate_frequent(df, candidates)]\n",
    "    if not frequent:\n",
    "        break\n",
    "    frequent_itemsets[k] = frequent\n",
    "    print(f\"Frequent {k}-itemsets: {frequent}\")\n",
    "    k += 1\n",
    "    candidates = generate_candidate(frequent, k)\n",
    "\n",
    "# Q2\n",
    "# Generate new sets\n",
    "def generate_sets(item_sets):\n",
    "    new_sets = []\n",
    "    for item_set in item_sets:\n",
    "        if 0 in item_set:\n",
    "            new_sets.append(frozenset(item_set))\n",
    "            for item in item_set:\n",
    "                if item == 0:\n",
    "                    new_sets.append(frozenset({item}))\n",
    "                    new_sets.append(frozenset(item_set - {item}))\n",
    "    return new_sets\n",
    "\n",
    "\n",
    "# Generate association rules\n",
    "def genarate_rules(Frequent_k, df, min_cof=0.75):\n",
    "    support_rate = calculate_support(df, generate_sets(Frequent_k))\n",
    "    for item_set in Frequent_k:\n",
    "        if 0 not in item_set:\n",
    "            continue\n",
    "        else:\n",
    "            for item in item_set:\n",
    "                if item == 0:                  \n",
    "                    cof = support_rate[frozenset(item_set)] / support_rate[frozenset(item_set - {item})]\n",
    "                    if cof < min_cof:\n",
    "                        continue\n",
    "                    else:\n",
    "                        lift = cof / support_rate[frozenset([0])] \n",
    "                        print(f\"{item_set-{item}}->{{{item}}}: cof = {cof}, lift = {lift}\")\n",
    "\n",
    "for k in list(frequent_itemsets.keys())[1:]:\n",
    "    genarate_rules(frequent_itemsets[k], df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
